\section{Multivariate triangular local limit theorem}
\label{sec:llt}

The goal of this section is to prove \cref{thm:multi-triangular-llt}. First, we recall some definitions. An $\R^d$-valued random variable $\vX$ is lattice if it is non-degenerate and is supported on the translation of some lattice. The symmetrisation of $\vX$ is given by $\vX^* = \vX_1 - \vX_2$ where $\vX_1$ and $\vX_2$ are independent copies of $\vX$. If $\vX$ is lattice, the main lattice of $\vX$ is given by
\begin{equation*}
    \lattice = \bigcup_{m=1}^{\infty} \left\{ 
        \textstyle \sum_{i=1}^m n_i \vx^*_i : \text{$n_i \in \Z$ and $\vx^*_i \in \supp(\vX^*)$ for all $i = 1, \ldots, m$}
    \right\}.
\end{equation*}
Now we restate \cref{thm:multi-triangular-llt}.
\llt*

Before we prove \cref{thm:multi-triangular-llt}, we first prove a sequence of lemmas. Our proof of the local limit theorem will use characteristic functions. Let $\vX$ be $\R^d$-valued. We use the convention that the characteristic function of $\vX$ is given by
\begin{equation*}
    \phi(\vu) = \E \left[ 
        e^{i \vu \cdot \vX}
    \right].
\end{equation*}
The following lemma shows the points at which the characteristic function of a lattice random variables attains 1 in absolute value can be precisely characterised when the main lattice is known. This is an adaptation of \cite[P.67, T1]{spitzerPrinciplesRandomWalk1964}.
\begin{lemma}
    \label{lem:cf-periodicity}
    Suppose $\vX$ is lattice with main lattice $\Z^d$ and characteristic function $\phi$. Then $\abs{\phi(\vu)} = 1$ if and only if $\vu \in (2 \pi \Z)^d$.
\end{lemma}
\begin{proof}
    If every coordinate of $\vu$ is a multiple of $2\pi$, then $\vu \cdot \vX$ has support in $t + 2 \pi \Z$ for some $t \in \R$. Therefore $e^{i\vu \cdot \vX}$ is constant and hence $\abs{\phi(\vu)} = 1$.
    
    For the converse, note the characteristic function of the symmetrisation $\vX^*$ satisfies
    \begin{equation*}
        \E\left[e^{i \vu \cdot \vX^*}\right]
        = \E\left[e^{i \vu \vX_1}\right] \E\left[e^{-i \vu \vX_2}\right]
        = \abs*{\E\left[e^{i \vu \vX}\right]}^2 = 1.
    \end{equation*}
    Thus $e^{i \vu \cdot \vx^*} \in 2 \pi \Z$ for all $\vx^*$ in the support of $\vX^*$. Since the fundamental lattice of $\vX$ is $\Z^d$, there exists $\vx^*_1, \ldots, \vx^*_m$ in the support of $\vX^*$ and $k_1, \ldots, k_m \in \Z$ such that
    \begin{equation*}
        \sum_{i=1}^m k_i \vx^*_i = (1, 0, \ldots, 0).
    \end{equation*}
    Therefore,
    \begin{equation*}
        u^{(1)} = \sum_{i=1}^m k_i \vu \cdot \vx^*_i \in 2 \pi \Z.
    \end{equation*}
    Repeating this argument for the other coordinates of $\vu$ shows all coordinates of $\vu$ are multiples of $2 \pi$.
\end{proof}

\begin{lemma}
    \label{lem:l2-cvgc-corrs}
    Suppose conditions (1) and (2) of \cref{thm:multi-triangular-llt} hold. Then, as $n \to \infty$, 
    \begin{equation*}
        \E[\vX_n] \to \E[\vX] \quad \text{and} \quad \cov(\vX_n) \to \cov(\vX).
    \end{equation*}
    Further for each $n$, let $\hat{\vX}_n = \vX_n - \E[\vX_n]$, and $\hat{\vX} = \vX - \E[\vX]$. Then the uniform integrability condition in \cref{eq:ui-condition} holds for the centered random variables $(\hat{\vX}_n)_{n \geq 1}$. This means that
    \begin{equation*}
        \label{eq:ui-mean-center}
        \lim_{L \to \infty} \sup_n \E\left[
            \norm{\hat{\vX}_n}^2
            \one \left\{ \norm{\hat{\vX}_n}^2 > L \right\}
        \right] = 0.
    \end{equation*}
\end{lemma}
\begin{proof}
    By Skorokhod's representation theorem, we can assume without loss of generality that $(\vX_n)_{n \geq 1}$ and $\vX$ are in the same probability space and $\vX_n \to \vX$ almost surely as $n \to \infty$. Then, the condition in \cref{eq:ui-condition} gives uniform integrability of $(\norm{\vX_n}_2^2)_{n \geq 1}$. Thus, by Vitali's convergence theorem, $\vX_n \to \vX$ in $L^2$ as $n \to \infty$. Therefore, $\vX$ has finite second moment and the mean and covariance of $\vX_n$ converge to that of $\vX$.

    Since the means converge, the centerings $\hat{\vX}_n \to \hat{\vX}$ in $L^2$ as $n \to \infty$ also. Thus, $(\norm{\hat{\vX}_n}_2^2)_{n \geq 1}$ is uniformly integrable by the converse statement in Vitali's theorem, as required.
\end{proof}

The following lemma shows that we have a normal central limit theorem.
\begin{lemma}
    \label{lem:clt}
    Suppose we are in the setting of \cref{thm:multi-triangular-llt}. Then
    \begin{equation*}
        \frac{1}{\sqrt{n}} \sum_{i=1}^n (\vX_{n, i} - \E[\vX_n]) \todist N(0, \Sigma)
    \end{equation*}
    as $n \to \infty$.
\end{lemma}
\begin{proof}
    We use the Lindeberg-Feller central limit theorem. We will use the notation $\Sigma = \cov(\vX)$, $\Sigma_n = \cov(\vX_n)$, $\hat{\vX}_{n, i} = \vX_{n, i} - \E[\vX_n]$ and $\hat{\vX}_n = \vX_n - \E[\vX_n]$. We will reduce the problem to the one-dimensional case. By the CramÃ©r--Wold device it is sufficient to show that 
    \begin{equation*}
        \frac{1}{\sqrt{n}} \sum_{i=1}^n \vu \cdot \hat{\vX}_{n, i} \todist
        N(0, \vu \cdot \Sigma \vu)
    \end{equation*}
    for all $\vu \in \R^d$. Define
    \begin{equation*}
        A_{n, i} = \frac{1}{\sqrt{n}} \vu \cdot \hat{\vX}_{n, i}.
    \end{equation*}
    Then by the version of the Lindeberg--Feller central limit theorem stated by Durrett in \cite[P.128-129, Theorem 3.4.10]{durrettProbabilityTheoryExamples2019}, to complete the proof it suffices to check that
    \begin{enumerate}
        \item $\lim_{n \to \infty} \sum_{i=1}^n \E[A_{n, i}^2] = \vu \cdot \Sigma \vu$.
        \item For all $\epsilon > 0$, $\lim_{n \to \infty} \sum_{i=1}^n \E\Big[A_{n, i}^2 \one\left\{ \abs{A_{n, i}} > \epsilon \right\}\Big] = 0$.
    \end{enumerate}
    To check condition (1),
    \begin{align*}
        \lim_{n \to \infty} \sum_{i=1}^n \E[A_{n, i}^2]
        = \lim_{n \to \infty} \E\Big[ (\vu \cdot \hat{\vX}_n)^2 \Big]
        = \lim_{n \to \infty} \vu \cdot \Sigma_n \vu
        = \vu \cdot \Sigma \vu
    \end{align*}
    by \cref{lem:l2-cvgc-corrs}. To check condition (2), for all $\epsilon > 0$
    \begin{align*}
        \lim_{n \to \infty} \sum_{i=1}^n \E\Big[A_{n, i}^2 \one\left\{ \abs{A_{n, i}} > \epsilon \right\}\Big]
        &= \lim_{n \to \infty} \E\Big[ (\vu \cdot \hat{\vX}_n)^2 \one\left\{ (\vu \cdot \hat{\vX}_n)^2 > \epsilon^2 n \right\}\Big] \\
        &\leq \norm{\vu}^2 \lim_{n \to \infty} \E\Bigg[ \norm{\hat{\vX}_n}^2 \one\left\{ \norm{\hat{\vX}_n}^2 > \frac{\epsilon^2}{\norm{\vu}^2} n \right\}\Bigg] \\
        &\leq \norm{\vu}^2 \lim_{n \to \infty} \sup_k \E\Bigg[ \norm{\hat{\vX}_k}^2 \one\left\{ \norm{\hat{\vX}_k}^2 > \frac{\epsilon^2}{\norm{\vu}^2} n \right\}\Bigg] \\
        &= 0
    \end{align*}
    by \cref{eq:ui-mean-center}.
\end{proof}

The last lemma we prove provides bounds on the absolute value of the characteristic functions of $\vX_n$. This will be used to apply the dominated convergence theorem in the main proof.
\begin{lemma}
    \label{lem:dom-cf}
    Suppose we are in the setting of \cref{thm:multi-triangular-llt}. Moreover assume that the common main lattice $\lattice$ is $\Z^d$. Let $\phi_n(\vu)$ be the characteristic function of $\hat{\vX_n} = \vX_n - \E[\vX_n]$. Then there exist $\delta, c> 0$, $\rho \in (0, 1)$ and $N$ such that for all $n \geq N$
    \begin{enumerate}
        \item $\abs{\phi_n(\vu)} \leq 1 - c \norm{\vu}^2$ for all $\vu \in S(\delta)$, and
        \item $\abs{\phi_n(\vu)} \leq \rho$ for all $\vu \in S(\pi) \setminus S(\delta)$
    \end{enumerate}
    where, for all $r > 0$, $S(r) = [-r, r]^d$.
\end{lemma}

\begin{proof}
    Firstly we use a analytical lemma stated by Durrett in \cite[P.116, Lemma 3.3.19]{durrettProbabilityTheoryExamples2019}. By that lemma, there exists a constant $A > 0$ such that 
    \begin{equation*}
        \abs*{e^{ix} - \left(1 + i x - \tfrac{1}{2}x^2\right)} \leq A \min\{\abs{x}, 1\} x^2
    \end{equation*}
    for all $x \in \R$. Then applying this with $x = \vu \cdot (\vX_n - \E[\vX_n])$
    \begin{equation*}
        \abs{\phi_n(\vu)}
        \leq \abs*{1 - \tfrac{1}{2} \vu \cdot \cov(\vX_n) \vu } + R_n(\vu)
    \end{equation*}
    where
    \begin{equation*}
        R_n(\vu) \leq A \E\left[ 
            \min\{\abs{\vu \cdot \hat{\vX}_n}, 1\} (\vu \cdot \hat{\vX}_n)^2
        \right].
    \end{equation*}
    We provide bounds on $R_n$ and $\abs{1 - \frac{1}{2} \vu \cdot \cov(\vX_n) \vu}$, starting with $\abs{1 - \frac{1}{2} \vu \cdot \cov(\vX_n) \vu}$.

    Let $\mineval_n$ and $\maxeval_n$ be the minimum and maximum eigenvalues of $\cov(\vX_n)$ respectively. Then, by standard theory for quadratic forms,
    \begin{equation*}
        \mineval_n \norm{\vu}^2
        \leq \vu \cdot \cov(\vX_n) \vu
        \leq \maxeval_n \norm{\vu}^2.
    \end{equation*}
    Moreover, let $\mineval$ and $\maxeval$ be the minimum and maximum eigenvalues of $\cov(\vX)$ respectively. The eigenvalues of a matrix are continuous in its entries and $\cov(\vX_n) \to \cov(\vX)$ by \cref{lem:l2-cvgc-corrs}. Therefore $\mineval_n \to \mineval$ and $\maxeval_n \to \maxeval$ as $n \to \infty$.

    We have assumed that $\cov(\vX)$ is non-degenerate thus $\mineval > 0$. Hence, there exists $N$ such that for all $n \geq N$,
    \begin{equation*}
        \frac{1}{2} \mineval \leq \mineval_n \leq \maxeval_n \leq 2 \maxeval.
    \end{equation*}
    There also exists $\delta_1 > 0$ sufficiently small that $\maxeval \norm{\vu}^2 < 1$ for all $\vu \in S(\delta_1)$. Then for all $n \geq N$ and $\vu \in S(\delta_1)$,
    \begin{equation}
        \abs*{1 - \tfrac{1}{2} \vu \cdot \cov(\vX_n) \vu }
        = 1 - \tfrac{1}{2} \vu \cdot \cov(\vX_n) \vu
        \leq 1 - \tfrac{1}{4} \mineval \norm{\vu}^2. \label{eq:qf-bound}
    \end{equation}
    To bound $R_n$, by the Cauchy-Schwarz inequality
    \begin{equation*}
        R_n(\vu) \leq A E_n(\vu) \norm{\vu}^2
        \quad \text{where} \quad
        E_n(\vu) = \E[\min\{\norm{\vu} \norm{\centeredX_n}, 1\} \norm{\centeredX_n}^2].
    \end{equation*}
    Then for all $L > 0$, splitting the expectation into the case where $\norm{\centeredX_n}^2 \leq L^2$ and the case when $\norm{\centeredX_n}^2 > L^2$,
    \begin{align*}
        \sup_n E_n(\vu)
        &\leq L^2 \min\{L \norm{\vu}, 1\} +
        \sup_n \E\left[ \norm{\centeredX_n}^2 \one\left\{ \norm{\centeredX_n}^2 > L^2 \right\}
        \right] \\
        &\to \sup_n \E\left[ \norm{\centeredX_n}^2 \one\left\{ \norm{\centeredX_n}^2 > L^2 \right\}
        \right] 
    \end{align*}
    as $\vu \to 0$. This holds for all $L > 0$, hence taking the limit $L \to \infty$ and using \cref{eq:ui-mean-center} we obtain that $\lim_{\vu \to 0} \sup_n E_n(\vu) = 0$. Thus, there exists $\delta_2$ such that for all $\vu \in S(\delta_2)$
    \begin{equation}
        \label{eq:rn-bound}
        R_n(\vu) \leq \frac{1}{8} \mineval \norm{\vu}^2.
    \end{equation}
    Thus setting $\delta = \min\left\{ \delta_1, \delta_2 \right\}$, for all $n \geq N$ and $\vu \in S(\delta)$
    \begin{equation*}
        \abs{\phi_n(\vu)} \leq 1 - c \norm{\vu}^2,
    \end{equation*}
    where $c = \frac{1}{8} \mineval$.

    We now address the second bound. let $\phi$ be the characteristic function of $\vX$. We assume $\vX$ has main lattice $\Z^d$, thus $\abs{\phi(\vu)} = 1$ if and only if every entry of $\vu$ is a multiple of $2 \pi$ by \cref{lem:cf-periodicity}. In particular $\abs{\phi(\vu)} < 1$ for all $\vu \in S(\pi) \setminus S(\delta)$. $\phi$ is continuous and $S(\pi) \setminus S(\delta)$ is compact. Therefore there exists $\epsilon > 0$ such that $\sup_{\vu \in S(\pi) \setminus S(\delta)} \abs{\phi(\vu)} \leq 1 - \epsilon$.

    Since $\vX_n \todist \vX$ as $n \to \infty$, $\phi_n \to \phi$ uniformly on compact sets. Therefore there exists $N$ such that for all $n \geq N$
    \begin{equation*}
        \sup_{\vu \in S(\pi) \setminus S(\delta)} \abs{\phi_n(\vu)} \leq \rho = 1 - \tfrac{1}{2} \epsilon. \qedhere
    \end{equation*}
\end{proof}

We are finally ready to prove \cref{thm:multi-triangular-llt}

\begin{proof}[Proof of \cref{thm:multi-triangular-llt}]
    We first address the case where the main lattice of $\vX$ and all $\vX_n$ is $\Z^d$. The main trick in the proof is to notice that if $n$ is integer valued then
    \begin{equation*}
        \one\{n = 0\} = \frac{1}{2\pi} \int_{-\pi}^{\pi} e^{i n u} \dif u.
    \end{equation*}
    For all $\vy \in \vc_n + \Z^d$, $\sum_{i=1}^n \vX_{n, i} - \vy \in \Z^d$, so 
    \begin{align*}
        \P\left( \sum_{i=1}^n \vX_{n, i} = \vy \right)
        &= \E\left[ 
            \frac{1}{(2 \pi)^d} \int_{S(\pi)} e^{i \vu \cdot \left(\sum_{i=1}^n \vX_{n, i} - \vy\right)} \dif \vu
         \right] \\
        &= \frac{1}{(2 \pi)^d} \int_{S(\pi)} \phi_n(\vu)^n e^{-i \vu \cdot (\vy - n \E[\vX_n])} \dif \vu,
    \end{align*}
    where $\phi_n(\vu) = \E[e^{i \vu \cdot (\vX_n - \E[\vX_n])}]$ and $S(r) = [-r, r]^d$ for all $r > 0$. Recall
    \begin{equation*}
        \vx_n = n^{-1/2}(\vy - n \E[\vX_n]).
    \end{equation*}
    Then, changing variables with $\vs = \sqrt{n} \vu$,
    \begin{equation*}
        n^{d/2} \P\left( \sum_{i=1}^n \vX_{n, i} = \vy \right)
        = \frac{1}{(2 \pi)^d} \int_{S(\pi\sqrt{n})} \phi_n(\vs/\sqrt{n})^n e^{-i \vs \cdot \vx_n} \dif \vs.
    \end{equation*}
    By the Fourier inversion theorem,
    \begin{equation*}
        f(\vx) = \frac{1}{(2 \pi)^d} \int_{\R^d} \psi(\vs) e^{-i \vs \cdot \vx} \dif \vs
    \end{equation*}
    where $\psi$ is the characteristic function of the $N(0, \cov(\vX))$ distribution. Therefore
    \begin{align*}
        &\sup_{\vy \in \vc_n + \lattice} \abs*{
            n^{d/2} \P\left( \textstyle \sum_{i=1}^n \vX_{n, i} = \vy \right) - f(\vx_n)
            } \nonumber \\
        &\hspace{6em} = \sup_{\vy \in \vc_n + \lattice} \abs*{
            \int_{\R^d} \left(\one_{S(\pi \sqrt{n})}(\vs) \phi_n(\vs/\sqrt{n})^n - \psi(\vs)\right) e^{-i\vs \cdot \vx_n} \dif \vs
            } \\
        &\hspace{6em} \leq \int_{\R^d} \abs*{ \one_{S(\pi \sqrt{n})}(\vs) \phi_n(\vs/\sqrt{n})^n - \psi(\vs)} \dif \vs.
    \end{align*}
    We apply the dominated convergence theorem. To dominate the integrand, first note that $\psi$ is integrable. Secondly let $\delta$, $c$, $\rho$ and $N$ be as in \cref{lem:dom-cf}. For all $n \geq N$ and for all $\vs \in S(\delta \sqrt{n})$, 
    \begin{equation*}
        \abs{\phi_n(\vs/\sqrt{n})}^n
        \leq (1 - c \norm{s}^2/n)^n
        \leq e^{-c \norm{s}^2}.
    \end{equation*}
    Let $C = - \log(\rho)$. Note if $\vs \in S(\pi \sqrt{n})$ then $\norm{\vs}^2 \leq \pi^2 d n$. Thus for all $n \geq N$ and $\vs \in S(\pi \sqrt{n}) \setminus S(\delta \sqrt{n})$
    \begin{equation*}
        \abs{\phi_n(\vs/\sqrt{n})}^n
        \leq e^{-Cn} 
        \leq e^{- \frac{C}{\pi^2 d} \norm{\vs}^2}.
    \end{equation*}
    Hence for all $n \geq N$,
    \begin{equation*}
        \abs*{ \one_{S(\pi \sqrt{n})}(\vs) \phi_n(\vs/\sqrt{n})^n - \psi(\vs)}
        \leq e^{-c \norm{\vs}^2} + e^{- \frac{C}{\pi^2 d} \norm{\vs}^2} + \abs{\psi(\vs)}
    \end{equation*}
    where, in particular, the right hand side is integrable. By \cref{lem:clt},
    \begin{equation*}
        \phi_n(\vs/\sqrt{n})^n \to \psi(\vs)
    \end{equation*}
    as $n \to \infty$ for all $\vs \in \R^d$. Thus for all $\vs \in \R^d$
    \begin{equation*}
        \one_{S(\pi\sqrt{n})}(\vs) \phi(\vs/\sqrt{n})^n \to \psi(\vs)
    \end{equation*}
    as $n \to \infty$. Hence by the dominated convergence theorem
    \begin{equation*}
        \lim_{n \to \infty} \sup_{\vy \in \vc_n + \lattice} \abs*{
            n^{d/2} \P\left( \textstyle \sum_{i=1}^n \vX_{n, i} = \vy \right) - f(\vx_n)
            } = 0,
    \end{equation*}
    as required.

    Finally we generalise to any main lattice $\lattice$. Suppose that $\lattice$ is generated by the columns of the invertible matrix $A$. Then $A$, viewed as a linear transform, is a isomorphism mapping $\Z^d$ to $\lattice$. Thus $A^{-1}\vX_n$ and $A^{-1}\vX$ will have common lattice $\Z^d$ for all $n$. Moreover we can check the remaining assumptions of \cref{thm:multi-triangular-llt} still hold, thus uniformly for $\vy$ in the translation of $\lattice$ containing the support of $\sum_{i=1}^n \vX_{n, i}$,
    \begin{equation*}
        \P\Bigg(\sum_{i=1}^n A^{-1} \vX_{n, i} = A^{-1}\vy\Bigg)
        = \frac{1}{\sqrt{(2 \pi n)^{d} \det\tilde{\Sigma}}} \exp \left( 
            -\frac{1}{2} (A^{-1} \vx_n)^T \tilde{\Sigma}^{-1} (A^{-1} \vx_n)
        \right) + \littleo(n^{-d/2}).
    \end{equation*}
    where $\tilde{\Sigma} = \cov(A^{-1} \vX)$. This simplifies to
    \begin{equation*}
        \P\Bigg(\sum_{i=1}^n \vX_{n, i} = \vy\Bigg)
        = \frac{1}{\sqrt{(2 \pi n)^{d} \det\tilde{\Sigma}}} \exp \left( 
            -\frac{1}{2} \vx_n^T (A \tilde{\Sigma} A^T)^{-1} \vx_n 
        \right) + \littleo(n^{-d/2}).
    \end{equation*}
    We have that
    \begin{equation*}
        \tilde{\Sigma}
        = \cov(A^{-1} \vX)
        = A^{-1} \cov(\vX) (A^{-1})^T.
    \end{equation*}
    Therefore
    \begin{equation*}
        \det(\tilde{\Sigma}) = \det(A)^{-2} \det(\cov(\vX)) = \det(\lattice)^{-2} \det(\cov(\vX))
    \end{equation*}
    and so
    \begin{align*}
        \P\Bigg(\sum_{i=1}^n \vX_{n, i} = \vy\Bigg)
        &= \frac{\det(\lattice)}{\sqrt{(2 \pi n)^{d} \det(\cov \vX)}} \exp \left( 
            -\frac{1}{2} \vx_n^T \cov(\vX)^{-1} \vx_n 
         \right) + \littleo(n^{-d/2}),
    \end{align*}
    as required.
\end{proof}