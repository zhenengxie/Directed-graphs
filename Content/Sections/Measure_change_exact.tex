\subsection{Exact form of the measure change}

To determine the exact form of the measure change, we first need to know the law of the ordering of the first $R_n$ vertices. Let $\cI_n = \{i \in [n] : D_i^- > 0\}$. The first $R_n$ vertices we explore in \cref{alg:edfs} will have positive in-degree, thus there exists a random bijection $\Sigma_n: [R_n] \to \cI_n$ such that $\mathbf{\widehat{D}}_{n, i} = \vD_{\Sigma_n(i)}$ for $i = 1, \ldots, R_n$. 
\begin{lemma}
    $\Sigma_n$ has law given by
    \begin{equation*}
        \P(\Sigma_n = \sigma \mid \vD_1, \ldots, \vD_n)
        = \prod_{i=1}^{R_n} \frac{D^-_{\sigma(i)}}{\sum_{j=i}^{R_n} D^-_{\sigma(j)}}.
    \end{equation*}
    for all bijections $\sigma: [R_n] \to \cI_n$.
\end{lemma}
\begin{proof}
    In \cref{alg:edfs}, a vertex first becomes explored in two ways. Either it is at the start of an out-component or it is discovered when an out-half-edge is paired to one of its in-half-edges.

    Suppose we have explored $m$ vertices and $m < R_n$. If the next vertex is explored by pairing one of its in-half-edges, then we have chosen it with probability proportional to its in-degree since in- and out-half-edges are paired uniformly at random. Otherwise, it is at the start of a new out-component, and since $m < R_n$, there are still vertices of positive in-degree. Thus we still pick a new vertex with probability proportional to its in-degree.

    Therefore in all cases,
    \begin{align*}
        &\P(\Sigma_n(m+1) = \sigma(m+1) \mid \Sigma_n(1) = \sigma(1), \ldots, \Sigma_n(m) = \sigma(m), \vD_1, \ldots, \vD_n) \\
        =&  \frac{D^-_{\sigma(m+1)}}{\sum_{i \in \cI_n} D_i^- - \sum_{j=1}^m D^-_{\sigma(j)}}
        = \frac{D^-_{\sigma(m+1)}}{\sum_{j=m+1}^{R_n} D^-_{\sigma(j)}}.
    \end{align*} 
    From this, repeated applications of the definition of conditional probability yields the desired result.
\end{proof}

Next we establish the form of the measure change when we condition on the exact value of $R_n$ but not $\Delta_n = 0$.

\begin{lemma}
    \label{lem:exact-measure-change-no-conditioning}
    For all integers $0 \leq r \leq n$ and test functions $u: (\N \times \N)^r \times \N \to \R$,
    \begin{equation*}
        \E \left[ u\left( 
            \mathbf{\widehat{D}}_{n, 1}, \ldots, \mathbf{\widehat{D}}_{n, r}, \textstyle \sum_{i \in \cI_n^c} D_i^+
        \right) \,\middle\vert\, R_n = r \right] \\
        =
        \E \left[
            u\left( \vZ_1, \ldots, \vZ_r, \textstyle \sum_{i = 1}^{n-r} E_i^+ \right)
            \psi_r(\vZ_1, \ldots, \vZ_r)
        \right]
    \end{equation*}
    where
    \begin{equation*}
        \psi_r(\vk_1, \ldots, \vk_r) =
        \frac{1}{p^r} \prod_{i=1}^r \frac{(r - i + 1)\mu}{\sum_{j=i}^r k_i^-}.
    \end{equation*}
    and $E_1^+, E_2^+, \ldots$ are i.i.d.\ random variables such that $E_i^+$ has the same distribution as $D^+$ conditioned on $D^- = 0$. We take the sequences $(E_i^+)_{i \geq 1}$ and $(\vZ_i)_{i \geq 1}$ to be independent.
\end{lemma}

\begin{proof}
    For any $\vk_1, \ldots, \vk_m \in \N^+ \times \N$ for all $i$ and $s \in \N$.
    \begin{align*}
        & \P\left(\mathbf{\widehat{D}}_{n, 1} = \vk_1, \ldots, \mathbf{\widehat{D}}_{n, r} = \vk_r, \textstyle \sum_{i \in \cI_n^c} D_i^+ = s, R_n = r \right) \\
        =& \sum_{\substack{I \subset [n] \\ \abs{I} = r}} \sum_{\sigma: [r] \to I}
        \P\left(\vD_{\Sigma_n(1)} = \vk_1, \ldots, \vD_{\Sigma_n(r)} = \vk_r, \textstyle \sum_{i \in \cI_n^c} D_i^+ = s, \cI_n = I, \Sigma_n = \sigma \right)
    \end{align*}
    where the second summation is taken over all bijections $\sigma: [r] \to I$. We examine a single summand.
    \begin{align*}
        &\P\left(\vD_{\Sigma_n(1)} = \vk_1, \ldots, \vD_{\Sigma_n(r)} = \vk_r, \textstyle \sum_{i \in \cI_n^c} D_i^+ = s, \cI_n = I, \Sigma_n = \sigma \right) \\
        =&\P\left(
            \vD_{\sigma(j)} = \vk_j\ \text{for $j = 1, \ldots, r$},
            \textstyle \sum_{i \in I^c} D_i^+ = s,
            D^-_i = 0\ \text{for $i \in I^c$},
            \Sigma_n = \sigma
            \right)  \\
        =& \prod_{i=1}^r \frac{k_i^-}{\sum_{j=i}^r k_j^-}
        \times \prod_{i=1}^r \lambda_{\vk_i}
        \times \P\left( 
            \textstyle \sum_{i \in I^c} D_i^+ = s,
            D^-_i = 0\ \text{for $i \in I^c$}
         \right).
    \end{align*}
    where $\lambda_{\vk} = \P(\vD_1 = \vk)$. We have
    \begin{equation*}
        \P\left( 
            \textstyle \sum_{i \in I^c} D_i^+ = s,
            D^-_i = 0\ \text{for $i \in I^c$}
         \right)
         = (1-p)^{n-r} \P\left( 
             \textstyle \sum_{i=1}^{n-r} E^+_i = s
          \right).
    \end{equation*}
    Also
    \begin{align*}
        \prod_{i=1}^r \frac{k_i^-}{\sum_{j=i}^r k_j^-} \times \prod_{i=1}^r \lambda_{\vk_i}
        &= \prod_{i=1}^r \frac{k_i^-}{\mu} \lambda_{\vk_i} \times \prod_{i=1}^r \frac{\mu}{\sum_{j=i}^r k_j^-} \\
        &= \P(\vZ_1 = \vk_1, \ldots, \vZ_r = \vk_r)
        \times \prod_{i=1}^r \frac{\mu}{\sum_{j=i}^r k_j^-}.
    \end{align*}
    Therefore
    \begin{align*}
        & \P\left(\mathbf{\widehat{D}}_{n, 1} = \vk_1, \ldots, \mathbf{\widehat{D}}_{n, r} = \vk_r, \textstyle \sum_{i \in \cI_n^c} D_i^+ = s, R_n = r \right) \\
        =& \binom{n}{r} \times r!
        \times \prod_{i=1}^r \frac{\mu}{\sum_{j=i}^r k_j^-} \times (1-p)^{n-r}
        \times \P\left(\vZ_1 = \vk_1, \ldots, \vZ_r = \vk_r, \textstyle \sum_{i=1}^{n-r} E_i^+ = s \right) \\
        =& \binom{n}{r} p^r (1-p)^{n-r} \times \frac{1}{p^r} \prod_{i=1}^r \frac{(r-i+1) \mu}{\sum_{j=i}^r k_i^-}
        \times \P\left(\vZ_1 = \vk_1, \ldots, \vZ_r = \vk_r, \textstyle \sum_{i=1}^{n-r} E_i^+ = s \right).
    \end{align*}
    Finally dividing by $\P(R_n = r) = \binom{n}{r} p^r (1-p)^{n-r}$ gives the desired measure change.
\end{proof}

Using the previous lemma we can prove existence and give the exact form of the desired measure change $\phi^n_m$.

\begin{lemma}
    \label{lem:exact-measure-change}
    For all $m \leq n$ and test functions $u: (\N \times \N)^m \to \R$,
    \begin{equation*}
        \E \left[
            u\left( \mathbf{\widehat{D}}_{n, 1}, \ldots, \mathbf{\widehat{D}}_{n, m} \right)
            \one\{R_n \geq m\}
            \,\middle\vert\,
            \Delta_n = 0
        \right] \\
        =
        \E \left[
            u\left( \vZ_1, \ldots, \vZ_m \right)
            \phi^n_m(\vZ_1, \ldots, \vZ_m)
        \right],
    \end{equation*}
    where
    \begin{align*}
        \phi^n_m(\vk_1, \ldots, \vk_m) =
        \frac{1}{\P(\Delta_n = 0)} \E\left[ 
            \one \left\{ \Delta_{n-m} = \sum_{i=1}^m (k_i^+ - k_i^-) \right\}
            \prod_{i=1}^m \frac{(n - i + 1) \mu}{\sum_{j=1}^m k_j^- + \Xi_{n-m}^-}
        \right].
    \end{align*}
\end{lemma}

\begin{proof}
    By \cref{lem:exact-measure-change-no-conditioning}, for all $r \geq m$
    \begin{align*}
        &\E \left[ 
            u\left( 
                \mathbf{\widehat{D}}_{n, 1}, \ldots, \mathbf{\widehat{D}}_{n, m}
             \right)
            \one\{\Delta_n = 0\}
            \, \middle\vert \,
            R_n = r
         \right] \\
        =&\E \left[ 
            u\left( \vZ_1, \ldots, \vZ_m \right)
            \one \left\{ 
                \sum_{i=1}^r (Z_i^- - Z_i^+) - \sum_{i=1}^{n-r} E_i^+ = 0
             \right\}
             \frac{1}{p^r} \prod_{i=1}^r \frac{(r - i + 1) \mu}{\sum_{j=i}^r Z_j^-}
         \right] \\
        =&\E \left[ 
            u\left( \vZ_1, \ldots, \vZ_m \right)
            \E \left[ 
                \one \left\{ 
                    \sum_{i=1}^r (Z_i^- - Z_i^+) - \sum_{i=1}^{n-r} E_i^+ = 0
                \right\}
                \frac{1}{p^r} \prod_{i=1}^r \frac{(r - i + 1) \mu}{\sum_{j=i}^r Z_j^-}
                \, \middle \vert \,
                \vZ_1, \ldots, \vZ_m
             \right]
         \right] \\
        =&\E \left[ 
            u\left( \vZ_1, \ldots, \vZ_m \right)
            \tilde{\gamma}^{n, m}_r (\vZ_1, \ldots, \vZ_m)
         \right],
    \end{align*}
    where
    \begin{align*}
        \tilde{\gamma}^{n, m}_r (\vk_1, \ldots, \vk_m)
        &= \E \Bigg[ 
                \one \left\{ 
                    \sum_{i=1}^r (Z_i^- - Z_i^+) - \sum_{i=1}^{n-r} E_i^+ = 0
                \right\} \times \\
                &\hspace{5em}
                \frac{1}{p^r} \prod_{i=1}^r \frac{(r - i + 1) \mu}{\sum_{j=i}^r Z_j^-}
                \, \Bigg| \,
                \vZ_1 = \vk_1, \ldots, \vZ_m = \vk_m
        \Bigg] \\
        &= \E \Bigg[ 
            \one \left\{ 
                \sum_{i=m+1}^r (Z_i^- - Z_i^+) - \sum_{i=1}^{n-r} E_i^+ = \sum_{i=1}^m (k_i^+ - k_i^-)
            \right\} \times \\
            &\hspace{5em}
            \frac{1}{p^m} \prod_{i=1}^m \frac{(r - i + 1) \mu}{\sum_{j=i}^m k_j^- + \sum_{j=m+1}^r Z_j^-}
            \frac{1}{p^{r-m}} \prod_{i=m+1}^r \frac{(r - i + 1) \mu}{\sum_{j=i}^r Z_j^-}
        \Bigg] \\
        &= \E \Bigg[ 
            \one \left\{ 
                \sum_{i=1}^{r-m} (Z_i^- - Z_i^+) - \sum_{i=1}^{n-r} E_i^+ = \sum_{i=1}^m (k_i^+ - k_i^-)
            \right\} \times \\
            &\hspace{5em}
            \frac{1}{p^m} \prod_{i=1}^m \frac{(r - i + 1) \mu}{\sum_{j=i}^m k_j^- + \sum_{j=1}^{r-m} Z_j^-}
            \frac{1}{p^{r-m}} \prod_{i=1}^{r-m} \frac{(r - m - i + 1) \mu}{\sum_{j=i}^{r-m} Z_j^-}
        \Bigg],
    \end{align*}
    since $(\vZ_i)_{i=m+1}^r$ has the same law as $(\vZ_i)_{i=1}^{r-m}$. Then applying \cref{lem:exact-measure-change-no-conditioning} again shows that
    \begin{align*}
        \tilde{\gamma}^{n, m}_r (\vk_1, \ldots, \vk_m)
        &= \E \Bigg[ 
            \one \left\{ 
                \sum_{i=1}^{r-m} (\widehat{D}_{n-m,i}^- - \widehat{D}_{n-m,i}^+) - \sum_{i \in \cI_{n-m}^c} D_i^+ = \sum_{i=1}^m (k_i^+ - k_i^-)
            \right\} \times \\
            &\hspace{8em}
            \frac{1}{p^m} \prod_{i=1}^m \frac{(r - i + 1) \mu}{\sum_{j=i}^m k_j^- + \sum_{j=1}^{r-m} \widehat{D}_{n-m,j}^-}
            \Biggm|
            R_{n-m} = r-m
        \Bigg].
    \end{align*}
    Conditional on $R_{n-m} = r-m$, we have
    \begin{equation*}
        \sum_{j=1}^{r-m} (\widehat{D}_{n-m,j}^- - \widehat{D}_{n-m,j}^+) - \sum_{i \in \cI_{n-m}^c} D_i^+ = \Delta_{n-m}
        \quad \text{and} \quad
        \sum_{j=1}^{r-m} \widehat{D}_{n-m, j}^- = \Xi^-_{n-m}.
    \end{equation*}
    Therefore,
    \begin{align*}
        \tilde{\gamma}^{n, m}_r (\vk_1, \ldots, \vk_m)
        &= \E \left[
            \frac{1}{p^m} \prod_{i=1}^m \frac{(r - i + 1) \mu}{\sum_{j=i}^m k_j^- + \Xi_{n-m}^-} \one_{\lltEvent_n}
            \, \middle \vert \,
            R_{n-m} = r-m
        \right],
    \end{align*}
    where
    \begin{equation*}
        \lltEvent_n=\lltEvent_n(\vk_1, \ldots, \vk_m) = \left\{ \Delta_{n-m} =  \sum_{i=1}^m (k_i^+ - k_i^-) \right\}.
    \end{equation*}
    Hence,
    \begin{align*}
        \E \left[ 
            u\left( 
                \mathbf{\widehat{D}}_{n, 1}, \ldots, \mathbf{\widehat{D}}_{n, m}
             \right)
            \one\{R_n \geq m, \Delta_n = 0\}
         \right]
        =\E \left[ 
            u\left( \vZ_1, \ldots, \vZ_m \right)
            \tilde{\phi}^n_m(\vZ_1, \ldots, \vZ_m)
         \right],
    \end{align*}
    where
    \begin{align*}
        &\tilde{\phi}^n_m(\vk_1, \ldots, \vk_m) \\
        =& \sum_{r=m}^n \binom{n}{r} p^r (1-p)^{n-r} 
        \E \left[
            \frac{1}{p^m} \prod_{i=1}^m \frac{(r - i + 1) \mu}{\sum_{j=i}^m k_j^- + \Xi_{n-m}^-} \one_{\lltEvent_n}
            \, \middle \vert \,
            R_{n-m} = r-m
        \right] \\
        =& \sum_{l=0}^{n-m} \binom{n}{l+m} p^{l+m} (1-p)^{n-m-l} 
        \E \left[
            \frac{1}{p^m} \prod_{i=1}^m \frac{(l + m - i + 1) \mu}{\sum_{j=i}^m k_j^- + \Xi_{n-m}^-} \one_{\lltEvent_n}
            \, \middle \vert \,
            R_{n-m} = l
        \right].
    \end{align*}
    We wish to view the sum as an expectation over $R_{n-m}$. In order to do this, we rewrite the expression so that we are taking a sum over the probabilities of a $\text{Binomial}(n-m, p)$ distribution. We can calculate
    \begin{equation*}
        \frac{\binom{n}{l+m} p^{l+m} (1-p)^{n-m-l}}{\binom{n-m}{l} p^l (1-p)^{n-m-l}}
        = p^m \prod_{i=1}^m \frac{(n-i+1)}{(l+m-i+1)}.
    \end{equation*}
    Therefore,
    \begin{align*}
        \tilde{\phi}^n_m(\vk_1, \ldots, \vk_m)
        &= \sum_{l=1}^{n-m} \binom{n-m}{l} p^l (1-p)^{n-m-l}
        \E \left[
            \prod_{i=1}^m \frac{(n - i + 1) \mu}{\sum_{j=i}^m k_j^- + \Xi_{n-m}^-} \one_{\lltEvent_n}
            \, \middle \vert \,
            R_{n-m} = l
        \right] \\
        &= \E\left[ 
            \E \left[
                \prod_{i=1}^m \frac{(n - i + 1) \mu}{\sum_{j=i}^m k_j^- + \Xi_{n-m}^-} \one_{\lltEvent_n}
                \, \middle \vert \,
                R_{n-m}
            \right]
         \right] \\
         &= \E \left[
            \prod_{i=1}^m \frac{(n - i + 1) \mu}{\sum_{j=i}^m k_j^- + \Xi_{n-m}^-} \one_{\lltEvent_n}
        \right].
    \end{align*}
    Finally, dividing by $\P(\Delta_n = 0)$ yields the desired form of $\phi^n_m$.
\end{proof}